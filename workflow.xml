<workflow-app name='test workfow' xmlns="uri:oozie:workflow:0.5">
    <start to='spark_test'/>
    <action name='spark_test'>
         <spark xmlns="uri:oozie:spark-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapreduce.framework.name</name>
                    <value>yarn</value>
                </property>
                <property>
                    <name>oozie.launcher.mapreduce.job.queue.name</name>
                    <value>${queue_name}</value>
                </property>
                <property>
                    <name>oozie.use.system.libpath</name>
                    <value>true</value>
                </property>
                <property>
                    <name>mapreduce.map.memory.mb</name>
                    <value>1024</value>
                </property>
                <property>oozie.launcher.mapreduce.amp.env
                    <value>PYSPARK_PYTHON=/root/.conda/envs/iabd1/bin/python</value>
                </property>
            </configuration>
            <master>${master}</master>
            <mode>${mode}</mode>
            <name>test</name>
            <jar>${app_path}/jobs/Extr_load_spotify.py</jar>
            <spark-opts> --master yarn --conf spark.scheduler.mode=FAIR --driver-memory=2g --executor-memory=2g --num-executors=2</spark-opts>
        </spark>
        <ok to="End"/>
        <error to="Kill"/>
    </action>
      <!--<action name='shell_test'>
      <shell xmlns="uri:oozie:shell-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapreduce.framework.name</name>
                    <value>yarn</value>
                </property>
                <property>
                    <name>oozie.launcher.mapreduce.job.queue.name</name>
                    <value>${queue_name}</value>
                </property>
                <property>
                    <name>mapreduce.map.memory.mb</name>
                    <value>1024</value>
                </property>
            </configuration>
            <exec>test.sh</exec>
            <argument>${data_path}</argument>
            <argument>${avrotools_filename}</argument>
            <argument>${schema_path}</argument>
            <file>${app_path}/test/test.sh</file>
            <file>${jar_path}/${avrotools_filename}</file>
        </shell>

        <ok to="End"/>
        <error to="Kill"/>
    </action> !-->
    <kill name='Kill'>
        <message>job failed: ${wf:errorCode('wordcount')}</message>
    </kill>
    <end name='End'/>
</workflow-app>

